<h2>Introduction</h2>
<p>Questioning what we believe and want is difficult at the best of times, and especially difficult when we most need to do it, but we can benefit from the informed opinions of others.</p>
<p>A deeper understanding of judgments and choices also requires a richer vocabulary than is available in everyday language.</p>
<p>We were far too willing to believe research findings based on inadequate evidence and prone to collect too few observations in our own research. 是的，人真的很容易相信不够具有统计有效性的发现😔</p>
<p>Because public interest is most easily aroused by dramatic events and by celebrities, media feeding frenzies are common.  哎😑 最近的疫情不就是吗</p>
<p>A recurrent theme of this book is that luck plays a large role in every story of success; it is almost always easy to identify a small change in the story that would have turned a remarkable achievement into a mediocre outcome. </p>
<p>...a puzzling limitation of our mind; our excessive confidence in what we believe we know, and our apparent inability to acknowledge the full extent of our ignorance and the uncertainty of the world we live in. We are prone to overestimate how much we understand about the world and to underestimate the role of chance events. <br></p>
<h2>2 Laziness is built deep into our nature<br></h2>
<p>&lt;Attention and effort&gt; p35<br>
As you become skilled in a task, its demand for energy diminishes. &lsqb;...&rsqb; Talent has similar effects. &lsqb;...&rsqb; A general “law of least effort” applies to cognitive as well as physical exertion. The law asserts that if there are several ways of achieving the same goal, people will eventually gravitate to the least demanding course of action. In the economy of action, effort is cost, and the acquisition of skill is driven by the balance of benefits and costs. Laziness is built deep into our nature.</p>
<h2>3 The lazy controller <br></h2>
<p>&lt;chapter 4&gt;<br>
<ul>
<li>...self control requires attention and effort.<br>
<li>...all variants of voluntary effort - cognitive, emotional, or physical - draw at least partly on the same pool of mental energy. <br>
<li>...the idea of mental energy is more than a mere metaphor. The nervous system consumes more glucose than most other parts of the body, and effortful mental activity appears to be especially expensive in the currency of glucose.<br>
<li>...a recurrent theme of this book: many people are overconfident, prone to place too much faith in their intuitions. They apparently find cognitive effort at least mildly unpleasant and avoid it as much as possible. <br>
<li>Intelligence is not only the ability to reason; it is also the ability to find relevant material in memory and to deploy attention when needed.</p>
</ul>
<p>这一点最近深有体会，注意力越来越难集中，这样不好。要改正。</p>
<h2>4 The associative machine<br></h2>
<p>Kahneman uses an example of banana and vomit to discuss the automatic responses of system 1 where associative activation takes place. This is interesting and also a bit foreign, because I realized that I don’t experience that whole complex of responses when the words are in a foreign language. When I tried to recreate the scenario but with the words in my native language, the responses are more automatic and intense. It’s interesting how  different systems are triggered when signals are presented in different languages. It seems that system 2 (the more effortful one) is more often used when faced with a non-native language, and that would explain perceived differences in argumentation and general communication patterns  across different languages. For me at least, speaking in my non-native language sometimes forces my thoughts to be more rational and organized, although the line is gradually blurring. </p>
<p>“In <em>An Enquiry Concerning Human Understanding</em>, published in 1748, the Scottish philosopher David Hume reduces the principles of association to three: resemblance, contiguity in time and space, and causality.”</p>
<p>“Furthermore, only a few of the activated ideas will register in consciousness; most of the work of associative thinking is silent, hidden from our conscious selves. The notion that we have limited access to the workings of our minds is difficult to accept because, naturally, it is alien to our experience, but it is true: you know far less about yourself than you feel you do.” <br>
...and this makes self-discovery worthwhile and fun. </p>
<p>“&lsqb;...&rsqb;priming is not restricted to concepts and words. &lsqb;...&rsqb; you must accept the alien idea that your actions and your emotions can be primed by events of which you are not even aware.” <br>
(example: John Bargh, the “Florida effect”)<br>
“This remarkable priming phenomenon -- the influencing of an action by the idea -- is known as the ideomotor effect.” <br>
It’s scary to think about the possibility of people who understand this effect and apply it to manipulate others for their own gains...<br>
“The ideomotor link also works in reverse. &lsqb;...&rsqb; Reciprocal links are common in the associative network. For example, being amused tends to make you smile, and smiling tends to make you feel amused. &lsqb;...&rsqb; You can see why the common admonition to ‘act calm and kind regardless of how you feel’ is very good advice: you are likely to be rewarded by actually feeling calm and kind.”<br>
Yes, happy and positive emotion and expression are self-reinforcing. Somewhat similar to “fake it till you make it”. </p>
<p>“Money-primed people become more independent than they would be without the associative trigger. &lsqb;...&rsqb; Money-primes people are also more selfish. &lsqb;...&rsqb; The general theme of these findings is that the idea of money primes individualism: a reluctance to be involved with others, to depend on others, or to accept demands from others.” </p>
<p>“Feeling that one’s soul is stained appears to trigger a desire to cleanse one’s body, an impulse that has been dubbed the ‘Lady Macbeth effect’.” </p>
<p>“More important, you must accept that they are true about <em>you</em>. &lsqb;...&rsqb; You do not believe that these results apply to you because they correspond to nothing in your subjective experience. But your subjective experience consists largely of the story that your System 2 tells itself about what is going on. Priming phenomena arise in System 1, and you have no conscious access to them.” </p>
<h2>5. Cognitive Ease<br></h2>
<p>“&lsqb;...&rsqb; predictable illusions inevitably occur if a judgment is based on an impression of cognitive ease or strain. &lsqb;...&rsqb; A reliable way to make people believe in falsehoods is frequent repetition, because familiarity is not easily distinguished from truth. &lsqb;...&rsqb; If you cannot remember the source of a statement, and have no way to relate it to other things you know, you have no option but to go with the sense of cognitive ease.” <br>
无关紧要的言论这样就算了，但是如果是重要的言论，还是要靠system 2去检查验证的。</p>
<p>论如何写出人让人信服的信息<br>
前提: “It is entirely legitimate for you to enlist cognitive ease to work in your favor, and studies of <em>truth</em> <em>illusions</em> provide specific suggestions that may help you achieve this goal.”<br>
“The general principle is that anything you can do to reduce cognitive strain will help, so you should first maximize legibility.” <br>
“If you care about being thought credible and intelligent, do not use complex language where simpler language will do.”<br>
<ul>
<li>下面这段让我在飞机上笑傻了：“In an article titled ‘<strong>Consequences of Erudite Vernacular Utilized Irrespective of Necessity: Problems with Using Long Words Needlessly</strong>’, he &lsqb;Princeton Professor Danny Oppenheimer&rsqb; showed that couching familiar ideas in pretentious language is taken as a sign of poor intelligence and low credibility.”
</ul>
“In addition to making your message simple, try to make it memorable. Put your ideas in verse if you can; they will more likely to be taken as truth.”<br>
“Finally, if you quote a source, choose one with a name that is easy to pronounce.”<br>
当然这些都是在信息真实的前提下: “High quality paper, bright colors, and rhyming or simple language will not be much help if your message is obviously nonsensical, or if it contradicts facts that your audience knows to be true.”</p>
<p>难点在于“the sense of ease or strain has multiple causes, and it is difficult to tease them apart.” 但是希望还是有的，“Difficult, but not impossible.”</p>
<p>Speaking of cognitive ease:<br>
<ul>
<li>“Familiarity breeds liking. This is a mere exposure effect.”
</ul>
</p>

<h2>6 Norms, surprises, and causes</h2>
<p>“We are able to communicate with each other because our knowledge of the world and our use of words are largely shared.” <br>
所以世界观差太多的人交流困难啊🌝</p>
<p>“Finding such causal connections is part of understanding a story and is an automatic operation of System 1. ”<br>
“In fact, all the headlines do is satisfy our need for coherence: a large event is supposed to have consequences, and consequences need causes to explain them. We have limited information about what happened on a day, and System 1 is adept at finding a coherent causal story that links the fragments of knowledge at its disposal.”<br>
人总有make sense of things的天性啊。想起来以前和大学室友讨论的遇到一些麻烦的影响重大的事情有时候会需要rationalize。不过这些毕竟是自己给自己圆的故事，不能等同事实。</p>
<p>“The perception of intention and emotion is irresistible &lsqb;...&rsqb; Your mind is ready and even eager to identify agents, assign them personality traits and specific intentions, and view their actions as expressing individual propensities. ”<br>
人也总有把其他物品或者生物拟人化的倾向，细想觉得很神奇。</p>
<p>“&lsqb;...&rsqb; people are prone to apply causal thinking inappropriately, to situations that require statistical reasoning.”<br>
好好学统计概率，对于减少直觉判断的错误有帮助🌝</p>
<h2>7 - A machine for jumping to conclusions<br></h2>
<p>“System 1 is gullible and biased to believe, System 2 is in charge of doubting and unbelieving, but System 2 is sometimes busy, and often lazy.”</p>
<p><em>Confirmation bias:</em><br>
“Contrary to the rules of philosophers of science, who advise testing hypotheses by trying to refute them, people (and scientists, quite often) seek data that are likely to be compatible with the beliefs they currently hold.”</p>
<p><em>Halo effect:</em> <br>
“The tendency to like (or dislike) everything about a person -- including things you have not observed -- is known as the halo effect. &lsqb;...&rsqb; It is one of the ways the representation of the world that System 1 generates is simpler and more coherent than the real thing.” <br>
因为某个方面喜欢一个人，就会自动幻想他其他方面也是理想的样子。<br>
“The sequence in which we observe characteristics of a person is often determined by chance. Sequence matters, however, because the halo effect increases the weight of first impressions, sometimes to the point that subsequent information is mostly wasted.”<br>
所以说在还没有非常了解的时候就喜欢上一个人很多时候是随机事件，好像赌博一样，取决于先看到了这个人的哪一面。如果是好的一面印象很深，那么之后看到的不好的面可能就自动或者刻意忽视掉。</p>
<p><em>Bias reduction:</em><br>
“To derive the most useful information from multiple sources of evidence, you should always try to make these sources independent of each other.”<br>
“&lsqb;...&rsqb; before an issue is discussed, all members of the committee should be asked to write a very brief summary of their position. &lsqb;...&rsqb; The standard practice of open discussion gives too much weight to the opinions of those who speak early and assertively, causing others to line up behind them.”<br>
嗯，让每个人都能独立发声不受那些声音最大的人的影响，是很难却很重要的。</p>
<p><em>What you see is all there is (WYSIATI):</em><br>
“The measure of success for System 1 is the coherence of the story it manages to create. The amount and quality of the day on which the story is based are largely irrelevant.”<br>
很遗憾，现在很多生物学研究甚至发表也都是看故事的一致性。<br>
“It is the consistency of the information that matters for a good story, not its completeness. Indeed, you will often find that knowing little makes it easier to fit everything you know into a coherent pattern.”<br>
“They didn’t want more information that might spoil their story.”<br>
人经常选择性失明，只看到自己想看到的，只相信自己想相信的。拒绝看到事实，拒绝接收现实，也是自我防护体系吧？如果骗骗自己更容易，可以过的开心点，又何妨呢？可能是这样想的吧。</p>

<h2>8 How judgments happen<br></h2>
<p>“An underlying intensity allows matching across diverse dimensions.”<br>
最简单的例子是罪行和惩罚之间的对等。</p>
<p>“System 1 carries out many computations at any one time. Some of these are routine assessments that go on continuously. Whenever your eyes are open, your brain computes a three-dimensional representation of what is in your field of vision, complete with the shape of objects, their position in space, and their identity.” <br>
不知不觉大脑一直在对环境做3D建模，其实很神奇的，什么时候机器人可以做到这种程度就厉害了😎<br>
“In contrast to these assessments, other computations are undertaken only when needed: you do not maintain a continuous evaluation of how happy or wealthy you are &lsqb;...&rsqb;”<br>
“However, the control over intended computations is far from precise: we often compute much more than we want or need. I call this excess computation the <em>mental shotgun</em>.”</p>
<p>比如说<br>
“An intention to answer one question evoked another, which was not only superfluous but actually detrimental to the main task.”<br>
下面这个例子挺好玩的, 三句话让大家判断字面上的正误：<br>
<ul>
<li>Some roads are snakes.<br>
<li>Some jobs are snakes.<br>
<li>Some jobs are jails.
</ul>
“All three sentences are literally false. However, you probably noticed that the second sentence is more obviously false than the other two &lsqb;...&rsqb; The reason for the difference is that the two difficult sentences can be metaphorically true.”<br>
嗯尤其第三句😂</p>
<p>Speaking of judgment <br>
“Evaluating people as attractive or not is a basic assessment. You do that automatically whether or not you want to, and it influences you.”<br>
“This was a clear instance of a mental shotgun. He was asked whether he thought the company was financially sound, but he couldn’t forget that he likes their product.”<br>
是啊，这两点都经常发生🤣</p>

<h2>9 Answering an easier question <br></h2>
<p>这段话写的很好就全抄下来了<br>
“The normal state of your mind is that you have intuitive feelings and opinions about almost everything that comes your way. You like or dislike people long before you know much about them; you trust or distrust strangers without knowing why; you feel that an enterprise is bound to succeed without analyzing it. Whether you state them or not, you often have answers to questions that you do not completely understand, relying on evidence that you can neither explain or defend.”<br>
能意识到这一点就已经很好了，很多时候这些直观感受是很片面的不靠谱的🦆<br>
</p>
<!-- <audio controls>
  <source src="audios/ch9.m4a" type="audio/mp4">
</audio> -->
<p>Substituting questions <br>
“If a satisfactory answer to a hard question is not found quickly, System 1 will find a related question that is easier and will answer it.”<br>
“However,  lazy System 2 often follows the path of least effort and endorses a heuristic answer without much scrutiny of whether it is truly appropriate. &lsqb;...&rsqb; Furthermore, you may not realize that the target question was difficult, because an intuitive answer to it came readily to mind.”<br>
“&lsqb;...&rsqb; a judgment that is based on substitution will inevitably be biased in predictable ways.”<br>
要经常保持警惕，看看自己是不是做了替换，注入了偏见。</p>
<p>“The present state of mind looms very large when people evaluate their happiness.”<br>
这里他举了个很有趣的例子，一个实验表明下面这两个问题的顺序决定了它们的答案的相关性：<br>
<ul>
<li> How many dates did you have last month?<br>
<li> How happy are you these days?
</ul>
这个顺序导致相关性很高，反之很低～</p>
<p>“The psychologist Paul Slovic has proposed an <em>affect heuristic</em> in which people let their likes and dislikes determine their beliefs about the world.”<br>
是啊，喜欢的不喜欢的会影响世界观。</p>
<p>最后附上System 1的特点<br></p>
<img src="https://drive.google.com/uc?id=1QsPaXqzL0Qd_B6MTv32EMFY-Zqpd3Vrp" alt="Characteristics of System 1" width=400>
<h2>10 The law of small numbers <br></h2>
<p>“&lsqb;...&rsqb; extreme outcomes (both high and low) are more likely to be found in small than in large samples. &lsqb;...&rsqb; they are what scientists call artifacts, observations that are produced entirely by some aspect of the method of research -- in this case, differences in sample size.” <br>
“&lsqb;...&rsqb; ‘intuitions about random sampling appear to satisfy the law of small numbers, which asserts that the law of large numbers applies to small numbers as well.’ &lsqb;...&rsqb; recommendation that researchers regard their ‘statistical intuitions with proper suspicion and replace impression formation by computation whenever possible.’”<br>
做科研这点真真真太重要了。当然其他时候做判断也需要意识到这点。</p>
<p>“System 1 is not prone to doubt. &lsqb;...&rsqb; System 2 is capable of doubt &lsqb;...&rsqb; However, sustaining doubt is harder work than sliding into certainty. The law of small numbers is a manifestation of a general bias that favors certainty over doubt.”<br>
“We are prone to exaggerate the consistency and coherence of what we see. &lsqb;...&rsqb; System 1 &lsqb;...&rsqb; will produce a representation of reality that makes too much sense.” <br>
人总是喜欢确定性多于怀疑和不确定性。能用简单的故事和因果关系来和自己解释得通就会容易忽略真正事实的复杂性。</p>
<p>“Random processes produce many sequences that convince people that the process is not random after all.”<br>
“‘To the untrained eye,’ Feller remarks, ‘randomness appears as regularity or tendency to cluster.’”<br>
“The tendency to see patterns in randomness is overwhelming”<br>
“We are far too willing to reject the belief that much of what we see in life is random.”<br>
或许因为我们喜欢能够掌控生活的感觉～</p>
<p>最后总结太好了<br>
<ul>
<li>“The exaggerated faith in small samples is only one example of a more general illusion -- we pay more attention to the content of messages than to information about their reliability, and as a result end up with a view of the world around us that is simpler and more coherent than the data justify. Jumping to conclusions is a safer sport in the world of our imagination than it is in reality. ”<br>
<li>“Statistics produce many observations that appear to beg for causal explanations but do not lend themselves to such explanations. Many facts of the world are due to chance, including accidents of sampling. Causal explanations of chance events are inevitably wrong.”
</ul>
</p>

<h2> 11 Anchors <br></h2>
<p><code>[...] anchoring effect. It occurs when people consider a particular value for an unknown quantity before estimating that quantity. What happens is one of the most reliable and robust results of experimental psychology: the estimates stay close to the number that people considered -- hence the image of an anchor.”</code></p>
<h3>Anchoring as adjustment<br></h3>
<blockquote>
<p>“Amos liked the idea of an anchor-and-adjust heuristic as a strategy for estimating uncertain quantities: start from an anchoring number, assess whether it is too high or too low, and gradually adjust your estimate by mentally ‘moving’ from the anchor.  The adjustment typically ends prematurely, because people stop when they are no longer certain that they should move farther.”</p>
<p>“Nick Epley and Tom Gilovich found evidence that adjustment is a deliberate attempt to find reasons to move away from the anchor &lsqb;...&rsqb; Epley and Gilovich also confirmed that adjustment is an effortful operation. People adjust less (stay closer to the anchor) when their mental resources are depleted.”</p>
<p>🌰  “Insufficient adjustment neatly explains why you are likely to drive too fast when you come off the highway onto city streets -- especially if you are talking with someone as you drive.”</p>
</blockquote>
<h3>Anchoring as priming effect<br></h3>
<blockquote>
<p>“My hunch was that anchoring is a case of suggestion. This is the word we use when someone causes us to see, hear, or feel something by merely bringing it to mind.”</p>
<p>“&lsqb;...&rsqb; suggestion is a priming effect, which selectively evokes compatible evidence. &lsqb;...&rsqb; System 1 understands sentences by trying to make them true, and the selective activation of compatible thoughts produces a family of systematic errors that make us gullible and prone to believe too strongly whatever we believe. &lsqb;...&rsqb; System 1 tries its best to construct a world in which the anchor is the true number.”</p>
</blockquote>
<p>anchoring index = ( estimate| high anchor - estimate | low anchor ) / (high anchor - low anchor)  ---&gt; 一些研究实验表明此指标可以达到30%-50%并且有💰影响：<br></p>
<blockquote>
<p>“Powerful anchoring effects are found in decisions that people make about money, such as when they choose how much to contribute to a cause.”</p>
</blockquote>
<p>anchor不需要有任何信息量<br></p>
<blockquote>
<p>“However, a key finding of anchoring research is that anchors that are obviously random can be just as effective as potentially informative anchors.”</p>
</blockquote>
<p>容易被别有用心的人利用🌚<br></p>
<blockquote>
<p>“The psychological mechanisms that produce anchoring make us far more suggestible than most of us would want to be.” </p>
<p>加长版 “The main moral of priming research is that our thoughts and our behavior are influenced, much more than we know or want, by the environment of the moment. Many people find the priming results unbelievable, because they do not correspond to subjective experience. Many others find the results upsetting, because they threaten the subjective sense of agency and autonomy.” &lt;--- 我</p>
</blockquote>
<p>如何保护自己 🙅‍♀️<br></p>
<blockquote>
<p>“In general a strategy of deliberately ‘thinking the opposite’ may be a good defense against anchoring effects, because it negates the biased recruitment of thoughts that produces these effects.”</p>
<p>加长版 “You are always aware of the anchor and even pay attention to it, but you do not know how it guides and constrains your thinking, because you cannot imagine how you would have thought if the anchor had been different (or absent). However, you should assume that any number that is on the table has had an anchoring effect on you, and if the stakes are high you should mobilize yourself (your System 2) to combat the effect.”</p>
</blockquote>
<h2>12 The science of availability</h2>
<p><code>We defined the availability heuristic as the process of judging frequency by “the ease with which instances come to mind.”</code></p>
<p>除了频率，还有曝光度（例如明星离婚），戏剧性事件（例如飞机失事），个人经历。</p>
<p>要时刻保持警惕是一件琐事，但是做到这点可以促进夫妻关系以及其他合作项目🌝</p>
<blockquote>
<p>One of the best-known studies of availability suggests that awareness of your own biases can contribute to peace in marriages, and probably other joint projects.</p>
</blockquote>
<p>同理，也是因为availability bias大家经常容易感觉自己在合作项目中的实际付出比自己的分内之事要多，并且其他人没有足够的感激自己的付出。</p>
<p>他讲了一个很有趣的实验：1）实验对象被要求列出6个或者12个表现他们自己assertive的🌰，2）他们对自己的assertive的程度做出评价。结果是被要求列出6个例子的人对自己assertive程度的评价要高。而原因是这样的：因为大家发现自己要想出12个🌰比自己预期的还要困难很多（因为低估了回想这些🌰的困难程度），所以由此推断自己不是很assertive。<br>
同理如果被要求提供越多的论点支持一个选择，人们越容易对这个选择不自信。<br></p>
<blockquote>
<p>People are less confident in a choice when they are asked to produce e more arguments to support it.</p>
</blockquote>
<p>但是有趣的是如果这些实验对象被告知背景音乐会影响他们都回忆的流畅程度，那么以上现象就不存在了。也就是说如果外界给了他们一个随便什么理由来解释他们不容易回想自己assertive的🌰，他们就安然接受了，不再受availability bias影响。</p>
<p>另一个实验表面当人们自身受到判断影响的时候，人们会更多考虑能想到的🌰的数量多少而不是想到🌰的难易程度。</p>
<blockquote>
<p>The conclusion is that the ease with which instances come to mind is a System 1 heuristic, which is replaced by a focus on content when System 2 is more engaged. </p>
<p>&lsqb;...&rsqb; people who let themselves be guided by System 1 are more strongly susceptible to availability biases than others who are in a state of higher vigilance.</p>
</blockquote>
<p>有很多情况可以让人更容易被availability bias影响，其中包括让人感到有权利：<br></p>
<blockquote>
<p>Merely reminding people of a time when they had power increases their apparent trust in their own intuition.</p>
</blockquote>
<h2>13 Availability, emotion, and risk</h2>
<blockquote>
<p>&lsqb;...&rsqb; (Paul) Slovic eventually developed the notion of an affect heuristic, in which people make judgments and decisions by consulting their emotions: Do I like it? Do I hate it? How strongly do I feel about it? In many domains of life, Slovic said, people form opinions and make choices that directly express their feelings and their basic tendency to approach or avoid, often without knowing that they are doing so. The affect heuristic is an instance of substitution &lsqb;...&rsqb; <br>

<br>The affect heuristic simplifies our lives by creating a world that is much tidier than reality.</p>
</blockquote>
<h3>The public and the experts </h3>
<p><br>这里的讨论太精彩也太应景了，作者给出了两方面的看法，先说Paul Slovic。他不觉得风险是客观的：
<blockquote>
Human beings have invented the concept of “risk” to help them understand and cope with the dangers and uncertainties of life. Although these dangers are real, there is no such thing as “real risk” or “objective risk.”
</blockquote>
他认为风险评估取决于如何衡量，而这个衡量的决策是受结果如何影响的，也就是说，定义风险其实是执行权力。他还说：
<blockquote>
&lsqb;...&rsqb; policy is ultimately about people, what they want and what is best for them. Every policy question involves assumptions about human nature, in particular about the choices that people may make and the consequences of their choices for themselves and for society.
</blockquote>
可惜，很多人在做决定的时候连对自己的后果都不太考虑，更何况给社会给别人带来的影响了😏迎合个人偏好和恐惧，那还需要社会契约吗？需要政府吗？<br></p>

<p><br>下面Kahneman讲了另一个人Cass Sunstein的看法，很大程度上是和Slovic相反的。不同于心理学家Slovic，Sunstein是一个知名法律学者。他认为风险可以客观衡量。
<blockquote>
His view is that the existing system of regulation in the United States displays a poor setting of priorities, which reflects reaction to public pressure more than careful objective analysis.
</blockquote>
而且这也很不公平啊，发声最响的人会得到最多的注意力。而其他更重要更危机的需求反而没有得到足够的注意力和资源。
<blockquote>
He starts from the position that risk regulation and government intervention to reduce risks should be guided by rational weighting of costs and benefits, and that the natural units for this analysis are the number of lives saved (or perhaps the number of life-years saved, which gives more weight to saving the young) and the dollar cost to the economy.
</blockquote>
很心酸的想到意大利🇮🇹前一阵估计就在做这些计算，并且估计算的是life-years😞
<blockquote>
Sunstein came to believe that biased reactions to risks are an important source of erratic and misplaced priorities in public policy.
</blockquote>
尽管书中讨论的重点和举的🌰都是人们不理智的高估了某些事件的风险，但是放在当下的情形，反过来看，道理是一样的。<br>
Sunstein说人们似乎不是很擅长评估小的风险，要不无视要不过激反应。对于很大的风险，似乎人们也是一样的 =&gt;强行无视或者不理智的囤货/歧视。
</p>

<p><br>对于公共决策的影响的对比：
<blockquote>
Cass Sunstein would seek mechanisms that insulate decision makers from public pressures, letting the allocation of resources be determined by impartial experts who have a broad view of all risks and of the resources available to reduce them.
</blockquote>
确实过于理想化，但是我更赞同。
<blockquote>
Paul Slovic trusts the experts less and the public somewhat more than Sunstein does, and he points out that insulating the experts from the emotions of the public produces that the public will reject -- an impossible situation in democracy.
</blockquote>
说的没错，完全的民主体制下Sunstein的主张很难执行。但是我不认同下面这句话。保护人们的恐惧？不对，应该去加强普遍教育，尽可能少一点不理智的无脑言论和行为。
<blockquote>
Rational or not, fear is painful and debilitating (✓), and policy makers must endeavor to protect the public from fear, not only real dangers. (❌)
</blockquote>
</p>

<p>最后，活学活用，我很清楚我自己现在的观点完全受了availability bias影响 -- 眼下的疫情已经各地各层政府的应对政策。</p>
<h2>14 Tom W’s Specialty<br></h2>
<p>这一章是围绕着一个🌰展开的。Tom W是Kahneman笔下的一个研究生。实验对象被要求回答三个问题：<br>
<ol>
<li>排序Tom在读每个专业的可能性（给出了九个专业大类）；<br>
<li>读完一段由一个不一定可信的心理学家对于Tom的描述，排序Tom和每个专业的相似度；<br>
<li>再次排序Tom在读每个专业的可能性。</p>
</ol>
<p>Twist是，这段描述是根据典型的计算机系研究生🌚写的。结果是：对于第一问大家都是根据统计概率猜的，第二问大家是根据representativeness猜的，而第三问大家还是根据第二问答的，基本无视了回答第一问时考虑的基准概率。<br></p>
<blockquote>
Substitution was perfect in this case: there was no indication that the participants did anything else but judge representativeness. The question about probability (likelihood) was difficult, but the question about similarity was easier, and it was answered instead.
</blockquote>
如此通过representativeness得出的预测尽管常常有用
<blockquote>
... has important virtues: the intuitive impressions that it produces are often -- indeed, usually -- more accurate than chance guesses would be.
</blockquote>
比如行为看着友善的人很可能确实友善，年轻男性比年长女性更容易开车过猛。
</p>

<p>但是，representativeness也带来问题：
<ol>
<li>an excessive willingness to predict the occurrence of unlikely (low base-rate) events.
<li>insensitivity to the quality of evidence.
</ol>
应对办法就是时刻牢记Bayesian reasoning
<ol>
<li>Anchor your judgment of the probability of an outcome on a plausible base rate. <br>
<li>Question the diagnosticity of your evidence.
</ol>
</p>

<p>这个道理非常实际非常有用，我就经常提醒自己要时刻记住prior，也就是他说的base rate，不要被新的一个甚至不知道uncertainty的数据完全影响判断。不过确实很难，就像他说的<br></p>
<blockquote>
Don’t expect this exercise of discipline to be easy -- it requires a significant effort of self-monitoring and self-control.
</blockquote>
关于这一点，有趣的是另一个实验表明如果人在思考回答这些问题的时候被要求皱眉，那么被representativeness带偏的程度要低一些，因为皱眉提高了System 2的警惕性。不过这也就说明representativeness带来的偏见是由于System 2日常太懒了🌚
</p>
<h2>15 Linda: less is more<br></h2>
<p>又是围绕一个引起很大争议的🌰的一章：<br><br>
<code>Linda现在31岁，单身，直言，聪明。她以前学的哲学专业。学生时期很关注歧视和社会公正问题，并且参与了反核武器抗议。</code> <br><br>
看了这段介绍以后，实验对象被要求排序以下八个情形的可能性：<br>
<ol>
<li> 她是小学老师  <br>
<li> 她在书店工作，并且上瑜伽课  <br>
<li> 她积极参与女权运动  <br>
<li> 她是精神病的社工  <br>
<li> 她是女性投票者联盟的成员  <br>
<li> 她是银行柜员  <br>
<li> 她是保险销售  <br>
<li> 她是银行柜员并且积极参与女权运动 
</ol> 
<hr>
看过之前的内容的都猜到了，这个实验的重点在于6和8：8是6的子集，概率不可能比6大。但是结果呢？大多数人认为8比6可能性更大。<br>
他们为了验证，更进一步改变实验，单独挑出6和8让实验对象无其他干扰项在两者之间二选一，结果还是一样。<br>
Kahneman和Tversky把这个叫做<strong>conjunction fallacy</strong>：
<blockquote>
&lsqb;...&rsqb; a conjunction fallacy, which people commit when they judge a conjunction of two events &lsqb;...&rsqb; to be  more probable than one of the events &lsqb;...&rsqb; in a direct comparison.
</blockquote>
这种谬论的成因他认为归结于人们喜欢圆满一致的故事
<blockquote>
The most coherent stories are not necessarily the most probable, but they are plausible, and the notions of coherence, <em>plausibility</em>, and probability are easily confused by the unwary.
</blockquote>
所以增加＊相关＊细节有时候会让人更加信服，虽然严格上降低了事件概率，比如洪水vs加州地震带来的洪水。

<br><p>另一个🌰是让大家比较两组碟子的价值，其中A组有几个破损的，但是完好的碟子比B要多，所以价值应该严格高于A组。虽然实验对象在比较时正确的回答A组价值高，但是实验对象在分别评估时，给出的估值A要低于B。原因似乎是因为大家喜欢用平均值（典型例子）来思考，可是价值是加和。简单来说
<blockquote>
System 1 averages instead of adding.
</blockquote>
</p>

<p>
还有一个🌰表明大家在思考具体频率的时候（vs概率），更容易避免落入这个谬论：
<blockquote>
&lsqb;...&rsqb; the frequency representation, as it is known, makes it easy to appreciate that one group is wholly included in the other.
</blockquote>
</p>

<p>
最后一些反思，时刻保持警惕，共鸣：
<blockquote>
The laziness of System 2 is an important fact of life, and the observation that representativeness can block the application of an obvious logical rule is also of some interest.
</blockquote>
</p>

<p>
有趣的是因为实验和发现引起太大争议（批评），Kahneman在章尾很苦涩的说
<blockquote>
&lsqb;...&rsqb; but I have come to accept as a fact of life that the norms of debate in social sciences do not prohibit the political style of argument, especially when large issues are at stake -- and the prevalence of bias in human judgment is a large issue.
</blockquote>
当他多年后遇到一个坚定的批评者问对方为什么揪住这点时，对方说因为有趣，并且说这个Linda问题吸引了这么多注意力，Kahneman有什么可抱怨的呢？🌚拜托，不是所有人都是attention whore好么🌚
</p>
<h2>16 Causes trump statistics<br></h2>
<p>对于概率估计，两种基本比率会被差别对待：<br>
<ul>
<li>Statistical base rates are generally underweighted, and sometimes neglected altogether, when specific information about the case at hand is available. 
<li>Causal base rates are treated as information about the individual case and are easily combined with other case-specific information.</ul>
这是因为我们习惯用典型例子(stereotype)来代表每个类别，虽然stereotype有时很错，并且会带来严重后果，但是我们必须正视这一点：
<blockquote>
&lsqb;...&rsqb; the psychological facts cannot be avoided: stereotypes, both correct and false, are how we think of categories.
</blockquote>

<p>
我们都知道stereotype的问题，这是个贬义词，大家在很多情况下都（正确的）努力避免stereotype。但是这里Kahneman说的很好，我们也不能因此就说避免stereotype是没有费用的，而是说我们愿意为了改善社会状况提高平等而付出这个费用的代价。<br></p>
<blockquote>
The social norm against stereotyping, including the opposition to profiling, has been highly beneficial in creating a more civilized and more equal society. <br>
Resistance to stereotyping is a laudable moral position, but the simplistic idea that the resistance is costless is wrong. <br>
The costs are worth paying to achieve a better society, but denying that the cost exists, while satisfying to the soul and politically correct, is not scientifically defensible.</p>
</blockquote>
</p>

<p>
接下来他讲了一个很有趣的故事。一个心理学教授给学生们讲了一个实验。<br><br>
<code> 简单来说就是一群16人在一起讨论，轮流发言，每个人单独隔断。其中一个人是卧底，他在某次发言时假装突发癫痫然后求助。结果只有4个人出来救他，6个人一直没动，还有5个人在这个发作的人窒息了才出来。</code><br><br>
之后教授给学生看了两个人的采访视频，很普通的内容（没有额外的人格信息）。然后让学生猜测他们会不会去救人。
</p>

<p>结果是学生一边倒的都猜测这两个人会去救人，尽管他们刚刚学过这个实验，知道救人的概率很小。所以他们完全忽视了基本比率的信息。<br>
实验本身就很有意思<br>
<blockquote>
The lesson students are meant to take away is that some potent feature of the situation, such as the diffusion of responsibility, induces normal and decent people such as them to behave in a surprisingly unhelpful way.
</blockquote></p>

<p>
但是更深一层的问题是，学生都白学了。怎么能让他们学到呢？也不是没有办法，要刺激惊讶到他们。统计数据是惊讶不到他们的。要用具体🌰来刺激他们，比如反过来先不告诉他们结果，让他们猜完以后告诉他们这两个人没有帮助救人，再让他们猜群体救人比例时就会猜的准多了。<br>
按照原作者Nisbett &amp; Borgida的话说: <br>
<blockquote>
Subjects’ unwillingness to deduce the particular from the general was only matched by their willingness to infer the general from the particular.
</blockquote></p>

<p>
所以，要改变长期的信念很难，尤其是人性相关的，或许大家都容易盲目乐观相信自己的天性善良吧～<br></p>
<blockquote>
But even compelling causal statistics will not change long-held beliefs or beliefs rooted in personal experience.
</blockquote>
</p>
<h2>17 Regression to the mean</h2>
<p><code>The correlation coefficient  between two measures, which varies between 0 and 1, is a measure of the relative weight of the factors they share. &lsqb;...&rsqb; whenever the correlation between two scores is imperfect, there will be regression to the mean. </code></p>

<p>Kahneman的第一个🌰是以色列飞行员训练，教官发现表扬奖励会降低飞行员的下次表现，而批评职责则会提高他们的下次表现。Kahneman指出
<blockquote>
What he had observed is known as <em>regression to the mean</em>, which in that case was due to random fluctuations in the quality of performance. &lsqb;...&rsqb; The instructor had attached a causal interpretation to the inevitable fluctuations of a random process.
</blockquote>
</p>

<p>
有趣的是他由此引申到了人生🌚
<blockquote>
&lsqb;...&rsqb; the feedback to which life exposes us is perverse.  Because we tend to be nice to other people when they please us and nasty when they do not, we are statistically punished for being nice and rewarded for being nasty.
</blockquote>
对于这段话我保留意见，我不觉得人性也是回归均值的随机过程🌚更像是强化学习的过程，更适合用因果解释🌚当然这也可能是我的System 1在试图诱导我。</p>

<p>关于天分和运气这两句很到位所以框起来
<br><br><code>
success = talent + luck
great success = a little more talent + a lot of luck
</code><br><br>
人们总喜欢用（错误的）因果关系来解释均值回归现象，Kahneman这里举了几个体育表现的🌰。虽然我大体上认同这个道理和现象，但是我不能完全认同这只是随机过程和运气：毕竟每次表现不是独立事件，历史很可能会影响未来 - 需要autoregression模型🤔</p>

<p>人们对于回归似乎很难理解，他又举了个好玩的🌰：
<ul>
<li>高智商女性趋向于和比她们智商低的男人结婚。<br>
<li>夫妻智商的关联性不是完美的。</ul>
这两句话其实本质是一样的，但是第一句明显听起来更有趣更容易引起话题🌝 如果夫妻智商关联性不是100%，那么数学上必然就会发生高智商女性嫁给平均智商比她们低的男性。当然，反之亦然。
<blockquote>
&lsqb;...&rsqb; our mind is strongly biased towards causal explanations and does not deal well with “mere statistics.”
</blockquote>
要时刻谨记这一点，因为在科学研究中人们也经常遇到这个问题。就连经验丰富的科学家也会害怕落入陷阱，得出不可靠的因果推理🌝</p>
<h2>18 Taming intuitive predictions<br></h2>
<p>预测性判断有两种方式：<br><ul>
<li>根据查询数据，精确计算，明确分析<br>
<li>根据System 1的直觉</ul>
后者又分两种：<ul>
<li>从大量技能和经验得来的直觉（比如医生，消防员等）<br>
<li>从heuristics得来的直觉，经常涉及下意识的替换问题</ul>
</p>

<p>
直觉预测容易有很大偏差：往往过于自信和极端。虽然修正过的预测依然会有错误，但是减少了系统性偏差，使得错误会更小。至于如何得到没有偏差的预测判断，可以遵循以下步骤：<ol>
<li> predict baseline<br>
<li> make intuitive prediction based on presented evidence<br>
<li> estimate correlattion / confidence of the evidence<br>
<li> arrive at intermediate prediction between baseline and intuitive response</ol>
大多数时候这样的结果是一个比较moderate的预测，因为很少会遇到我们能够百分之百相信直觉判断的时候。这个修正方式其实是近似正规的统计分析的～</p>

<p>当然，作为严谨的Kahneman，他指出了caveat，也就是这样修正直觉判断是System 2的工作，而且是很辛苦的工作🌚<br></p>
<blockquote>
The effort is justified only when the stakes are high and when you are particularly keen not to make mistakes.
</blockquote>
并且要注意改正判断有时候会让人生更加复杂～要根据目标来决定，因为有时候减少偏差不是最重要的，比如风投人士可能更要避免错过下一个谷歌而不是减少投资一个失败的创业公司带来的一点点损失 -- 在这些情况下极端预测是被偏好的。
</p>

<p>当然，我们在放弃减少偏差时最好要清醒的意识到这一点：
<blockquote>
However, we are not all rational, and some of us may need the security of distorted estimates to avoid paralysis. If you choose to delude yourself by accepting extreme predictions, however, you will do well to remain aware of your self-indulgence.
</blockquote>
或许这些修正措施最大的贡献就是让我们必须思考我们的认知的限度。</p>

<p>最后，结尾有句话很有趣：<br>
<blockquote>
We will not learn to understand regression from experience.
</blockquote>
学会这一点并且让它深入骨髓很难，毕竟不是通过个人经验积累的思考认知方式内化起来比较困难。就好像上一章提到的十九世纪英国科学家Francis Galton花了几年时间才说服自己子女身高和父母没什么关系，只是regression to the mean。</p>

<h2>19 The illusion of understanding <br></h2>
<p>Nassim Taleb在他的黑天鹅书中提到了<strong><em>narrative fallacy</em></strong>: how flawed stories of the past shape our views of the world and our expectations for the future.
Kahneman此处拿Google的崛起作为🌰<br>
<blockquote>
<p>Of course there was a great deal of skill in the Google story, but luck played a more important role in the actual event than it does in the telling of it. And the more luck was involved, the less there is to be learned.</p>
</blockquote>
这就是应了之前讲到的WYSIATI原则(what you see is all there is)，扎心了：
<blockquote>
<p>You build the best possible story from the information available to you, and if it is a good story, you believe it. <br>
Paradoxically, it is easier to construct a coherent story whe you know little &lsqb;...&rsqb;</p>
</blockquote>
<code>
Our comforting conviction that the world makes sense rests on a secure foundation: our almost unlimited ability to ignore our ignorance.
</code><br></p>

<p><strong>Hindsight bias</strong> 是由于1）我们在意外事件发生以后会很快调整自己的观点，2）我们很不擅长重建自己曾经的但是被改变了的知识和观念。说白了就是事件发生以前我们怎么想的在事件发生以后很难准确回忆。以色列的Baruch Fischhoff做实验显示<br></p>
<blockquote>
<p>If an event had actually occurred, people exaggerated the probability that they had assigned to it earlier.</p>
</blockquote>
<p>Hindsight bias会带来很多问题，比如在判断决策质量时容易关注结果而不是决策过程本身的好坏。这对于经纪人性质的决策人来说尤其不利，比如说医生--人们往往容易把坏的结果怪罪于他们，而并不把好的结果归功于他们，典型的<strong>outcome bias</strong> 。结果越沉重，bias也越大。这些bias会导致决策人寻求官僚方案，极度避免风险，但是这样的结果也是好坏参半。当然这些认知偏差也不全是使人规避风险，另一方面看也奖赏那些幸运的冒险者--a few lucky gambles can crown a reckless leader with a halo of prescience and boldness. 🌚</p>
<p>成功的秘诀？（spoiler：运气比较重要）<br>
很喜欢这句话，智慧勇气不一定成功🌚
<br><code>We all have a need for the reassuring message that actions have appropriate consequences, and that success will reward wisdom and courage.</code><br><br>

<p>Kahneman举的例子是商业的成败，最后总结如下：<br>
<blockquote>
<p>Stories of how businesses rise and fall strike a chord with readers by offering what the human mind needs: a simple message of triumph and failure that identifies clear causes and ignores the determinative power of luck and the inevitability of regression. These stories induce and maintain an illusion of understanding, imparting lessons of little enduring value to readers who are all too eager to believe them.</p>
</blockquote>
咳咳，感觉讲商业成功秘诀的书主要卖的是希望，如果说成功与否主要看运气，书是会卖不出去的😂</p>
<h2>20 The illusion of validity</h2>
<p><code>For some of our most important beliefs we have no evidence at all, except that people we love and trust hold these beliefs. Considering how little we know, the confidence we have in ourselves is preposterous -- and it is also essential. </code><br>
&lsqb; 很有意思，我有时候觉得仿佛belief这个词本身有一种魔力，既然是信仰，信念，就不需要建立在客观证据之上，就好像根据定义来说它就不需要符合科学性。&rsqb;</p>
<p>关于illusion of validity他讲的第一个故事是当年在以色列通过一个障碍课程来预测未来军官训练的表现。看完学员们在障碍课程的表现以后他们得出了很强的印象和预测，但是事实表明他们的预测基本没用。最有趣的是即使知道了没用以后，在之后的观察预测中他们依然对自己的预测抱有很大信心：<br></p>
<blockquote>
<p>We knew as a general fact that our predictions were little better than random guesses, but we continued to feel and act as if each of our specific predictions was valid.</p>
</blockquote>
这映射了substitution和representativeness heuristic，还有之前提到的reluctance to infer the particular from the general。
<blockquote>
<p>Subjective confidence in a judgment is not a reasoned evaluation of the probability that this judgment is correct. Confidence is a feeling, which reflects the coherence of the information and the cognitive ease of processing it.</p>
</blockquote>
所以要时刻记住我们需要的是客观的confidence interval，而不是主观的自信🌚
</p>

<p><br>接下来他讲了金融行业所谓的选股技能其实是站不住脚的，比如专业人士并不能持续战胜市场。
<blockquote>
a major industry appears to be built largely on an illusion of skill.
</blockquote>
好玩的是他提到他学生Odean的两篇文章，一个叫做Trading is hazardous to your wealth（对一般的个人投资者来说主动交易有损收益） ，一个交做Boys will be boys（男性比女性更容易根据无用的想法进行交易而损失更多）。交易员的主观经验是他们在很大不确定性的情况下做出了最合理的猜测，然而这种猜测在高效的市场里不会比随机猜测好多少。 &lsqb; 不过市场很多时候并不高效，比如现在🌚 而且我在想，整体来说，如今信息量巨大，就算大家都有access（不一定），也不会都有分析的能力，所以其实本质上还是会有信息不对称性。&rsqb;<br>
Kahneman认为说到底是行业文化问题：
<blockquote>
<p>Facts that challenge such basic assumptions -- and thereby threaten people’s livelihood and self-esteem -- are simply not absorbed.</p>
</blockquote>
</p>

<p><br>
然后他又犀利指出所谓的专家也不过是人，容易对自己过于自信，并且讨厌错误。宾州大学心理学家Philip Tetlock在他的2005年的书Expert political judgment: how good is it? how can we know?中讲述了他采访284位专家的结果，他们的预测并不比well informed的普通人好多少：
<blockquote>
<p>We reach the point of diminishing marginal predictive returns for knowledge disconcertingly quickly.</p>
</blockquote>
</p>

<p><br>
章尾Kahneman又放松了语气
<blockquote>
<p>The main point of this chapter is not that people who attempt to predict the future make many errors; that goes without saying. 🌝</p>
</blockquote>
真正的课程是
<ol>
<li>Errors of prediction is inevitable because the world is unpredictable.<br>
<li>High subjective confidence is not to be trusted as an indicator of accuracy.</ol>
<p>他还说短期趋势可以被预测，而长期很难，但是两者间界限并不清楚。&lsqb; 或许我们只是需要取得更多的相关数据，建立更强大的模型？到极致不过是包括每个原子的模型。不过这又回到了人是不是有自由意志的问题😐 &rsqb;</p>
<h2>21 intuitions vs. formulas<br></h2>
<p>几十年前，Paul Meehl曾经在一本小书<em>Clinical vs. statistical prediction: a theoretical analysis and a review of the evidence</em> 里面指出<strong>专家预测很多时候不如简单算法准</strong> 。<br>
原因呢，Meehl认为是专家觉得自己很聪明，能用很复杂的模型来预测，但是其实这反而经常减少了有效性。在他看来，很少有情况适合用判断来代替公式，除非是那种“腿断了”的时候（broken-leg rule）。<br>
Kahneman认为另一个原因是人类面对复杂信息的判断很没有一致性，或许是因为System 1对于情境的很强依赖：
<blockquote>
<p>Because you have little direct knowledge of what goes on in your mind, you will never know that you might have made a different judgment or reached a different decision under very slightly different circumstances.</p>
</blockquote>
在不确定性高的时候，不一致性对于预测尤其致命。</p>

<p><br>在Meehl之后，Robert Dawes写了一篇著名文章<em>The robust beauty of improper linear models in decision making</em> , 观察指出复杂的统计算法相比简单的方法并没有什么附加价值。一个🌰是预测婚姻稳定的公式：<br>
<blockquote>
<code>frequency of lovemaking minus frequency of quarrels</code>
</blockquote>
（不要得到负的结果🌝）<br>
所以结论是简单算法经常可以和优化的复杂算法媲美，而且肯定可以胜过专家。他举了个预测新生儿有没有问题的简单公式(the Apgar test)的🌰。</p>

<p><br>当然这个结论招来很多批评反对。当人和机器竞争的时候，我们一般站在我们人类一边。这些偏见在重大问题上尤其明显。
<blockquote>
<p>Meehl and other proponents of algorithms have argued strongly that it is unethical to rely on intuitive judgments for important decisions if an algorithm is available that will make fewer mistakes.</p>
</blockquote>
虽然很有道理，但是不符合心理现实：
<blockquote>
<p>for most people, the cause of a mistake matters. The story of a child dying because an algorithm made a mistake is more poignant than the story of the same tragedy occurring as a result of human error, and the difference in emotional intensity is readily translated into a moral preference.</p>
</blockquote>
是啊，现在也是一样，对于AI的反对很多是基于算法的accountability，如果连透明度都没有，黑箱子算法出了错怎么办？<br>
当然Kahneman也有希望，随着越来越多算法被用来生活各处，大家的反感或许会慢慢降低。</p>

<p><br>最后，他讲了一个很多年前他在以色列军队帮助预测士兵对于战斗的适合度以及他们具体适合哪种部队的故事。他根据Meehl的结论设计了一个尽可能客观了解士兵各个维度的测试，然后综合打分，结果比以前靠面试者印象有很大提高。有趣的是，在完成这个比较客观的测试之后，面试者的预测也准了很多。
<blockquote>
<p>A more general lesson that I learned from this episode was do not simply trust intuitive judgment -- you own or that of others -- but do not dismiss it, either.</p>
</blockquote>
</p>
<h2>22 expert intuition: when can we trust it?<br></h2>
<p>先上结论<br>
<code>The answer comes from the two basic conditions for acquiring a skill:<br>
* an environment that is sufficiently regular to be predictable<br>
* an opportunity to learn these regularities through prolonged practice</code><br>
<p>这章Kahneman讲了他和Gary Klein的“most satisfying and productive adversarial collaboration”的故事，虽然两人观点不同，但是试图合作研究一个问题：什么情况下可以相信专家的直觉？<br>
两人对于直觉的观点因为过往经历不同而大相径庭。Kahneman受Paul Meehl影响对于专家的直觉不太认可。而Klein因为曾研究消防指挥的准确直觉而认为直觉很重要--他由此提出了recognition-primed decision决策理论：在第一阶段一个暂定的计划因为associative memory浮出脑海(System 1)，然后在第二个阶段这个计划在脑子里被模拟检验(System 2)。这个模型受到了决策理论创始人Herbert Simon的影响，Simon对于直觉的定义就是模式识别：
<blockquote>
The situation has provided a cue; this cue has given the expert access to information stored in memory, and the information provides the answer. <strong>Intuition is nothing more and nothing less than recognition</strong>.
</blockquote>
所以其实“不知道自己是怎么知道的”是精神生活的常态，不是直觉独有的特点。</p>

<p><br>既然直觉的可靠性依赖于实在的技能，那么我们是怎么培养技能的呢？我们很擅长情感学习，就像Pavlov的著名研究表面狗是可以学习希望的（听到铃声代表有食物）。人对于恐惧的学习尤其迅速（可能是进化需求？），不仅可以通过经验，还可以通过语言。但是专业技能比这种情感学习要花更久时间培养。Kahneman举了国际象棋的🌰，因为这些领域的专家要求的不仅是一项技能，而是一箩筐技能。他又举了个语言学习的🌰，相比国际象棋简单，但是也需要复合技能。他举了个很有意思的🌰：Lewis Carroll的名诗<em>Jabberwocky</em> ，虽然基本每个词都不认识，但是我们却可以很好的念出来～😆
<blockquote>
’Twas brillig, and the slithy toves<br>
Did gyre and gimble in the wabe<br>
All mimsy were the borogoves<br>
And the mome raths outgrabe
</blockquote>
</p>

<p><br>要特别注意的是人们自己对于自己直觉的自信程度不是衡量直觉可靠度的好标准。来复习一下：人们的自信源自于cognitive ease和coherence，而这两者绝不等同于客观有效性。<br>
要有可靠的直觉需要稳定的环境。回顾一下之前章节的🌰，比如金融分析师和临床诊断医师，他们的环境不稳定性高，所以本质上就很难有准确的估计（算法比人稍微好一些贵在算法可以更好的找到一些偏弱的信号并且比较不会自相矛盾🌚）。所以不能怪他们没法精准预测。但是做不好可以原谅，过于自大却不行🌝
<blockquote>
<p>However, it seems fair to blame professionals for believing they can succeed in an impossible task.</p>
</blockquote>
</p>

<p><br>最后关于为什么这么显而易见的结论花了他们俩七八年时间呢？
<blockquote>
<p>But this is what always happens when a project ends reasonably well: once you understand the main conclusion, it seems it was always obvious.</p>
</blockquote>
哈哈此处想到了hindsight bias。<br>
以及最后他们俩虽然学术见识达成一致，很多观念和喜好依然保持不同。可谓好的合作的典范了。
</p>
<h2>23 The outside view <br></h2>
<p>这章的故事讲的是当年他们一群人想设计一门新的课程给高中生讲判断和决策论，于是需要编著教材。某一个周五的下午，在大家讨论如何在有不确定性的情况下估计时，他问了大家一个问题，让大家估算他们的教材要花多久完成。大家猜的平均是两年左右。然后他又问了其中一个参与/熟悉很多其他教材编撰过程的专家，一般大家都会花多久，有多少项目最终没有完成，以及他们和那些项目比起来资源人力如何。得到的回答是有40%的没有完成，而那些完成的也一般需要7-10年，而他们比起那些项目在平均线下。大家听了以后却并没有做出任何深入的讨论或者改变/放弃计划。最终那个教材又花了八年完成。</p>

<p>这个故事告诉大家我们很容易陷入planning fallacy，使得我们的计划
<ul>
<li>are unrealistically close to best-case scenarios<br>
<li>could be improved by consulting the statistics of similar cases
</ul>
有时候这是因为我们很难想象我们本身计划之外会发生的事（厨房重新装修花的钱永远比计划多，因为总被推销新的功能）。另一些时候是因为一些人故意为之，为了想要让计划更容易被批准，比如公共建设项目的报价比实际花费低很多（导致最后超额）。
</p>

<p>那怎么可以减少这种谬论呢？方法是采取outside view而不仅仅是inside view。这是因为我们往往没法设想那些Donald Rumsfeld口中的 “<strong>the unknown unknowns</strong>”。所以需要依靠reference class来得到这一类事件的大概估算base rate，然后根据个例需要调整。说起来容易做起来难得很：
<blockquote>
<p>People who have information about an individual case rarely feel the need to know the statistics of the class to which the case belongs. <br>
“Pallid” statistical information is routinely discarded when it is incompatible with one’s personal impressions of a case.</p>
</blockquote>
更复杂的是这往往会被涉及到道德层面，比如说律师医生认为每个个例都是独特的与众不同的，不能只用统计数据说话🌚</p>

<p><br>另：Planning fallacy还可以引申到风险评估，因为人们往往过于乐观而低估风险，导致他们（不自知的）参与了风险过大的项目。</p>

<p><br>另另：irrational perseverance要不得。但是我们确实往往这样做：
<blockquote>
<p>Facing a choice, we gave up rationality rather than give up the enterprise.</p>
</blockquote>
我们知道sunk cost fallacy，但是想不到应用这个原则。我们甚至不愿意去想发生了什么，就像他们当时听了以后什么也没做。就像他说的
<blockquote>
<p>it will never be the natural thing to do.</p>
</blockquote>
</p>

<p><br>值得一提的是，他每章基本都会提到之前讲过的一些内容，帮助读者复习巩固，真贴心啊lol 比如这一章除了base rate neglect还复习了这个原则：
<blockquote>
<p>the proper way to elicit information from a group is not by starting with a public discussion but by confidentially collecting each person’s judgment.</p>
</blockquote>
</p>
<h2>24 The engine of capitalism<br></h2>
<p>这章讲的是乐观偏差。乐观的态度大部分是遗传的，这种看到事情好的一面的心态有很多好处，比如更受欢迎，更坚韧，更不容易抑郁，免疫系统更强，更容易感觉健康，活得更长😄但是除了这些，乐观的人也更多地影响社会，因为他们作为企业家会（不自知地）承担更多风险。
<blockquote>
<p>Their confidence in their future success sustains a positive mood that helps them obtain resources from others, raise the morale of their employees, and enhance their prospects of prevailing.</p>
</blockquote>
事实表明这种乐观心态很常见，很固执，对于失败的创业者成本也很高。其实对于大企业的ceo也是一样，他们经常由于过于乐观自负而承担过多风险，比如并购其他公司的时候。</p>

<p>这种创业的乐观主义是System 1的WYSIATI的表现，其中有一部分原因是忽略竞争（<strong>competition neglect</strong> ）：<ul>
<li>We focus on our goal, anchor on our plan, and <em>neglect relevant base rates</em> , exposing ourselves to the <strong><em>planning fallacy</em></strong>.<br>
<li>We focus on what we want to do and can do, <em>neglecting the plans and skills of others.</em> <br>
<li>Both in explaining the past and in predicting the future, we focus on the causal role of skill and <em>neglect the role of luck</em> . We are therefore prone to an <strong><em>illusion of control</em></strong>.<br>
<li>We focus on what we know and <em>neglect what we do not know</em>, which makes us overly confident in our beliefs.</ul>
这就好像90%的人都觉得自己比平均驾驶水平高。其实一个创业公司的成败很大程度上取决于竞争对手和市场变化。有意思的是，虽然这种过于乐观的人会给他们自己和他们的投资者带来损失，但是对于整个经济可能是好的，因为他们可能会吸引来更有能力的竞争者。</p>

<p>从社会心理学的角度看，有些时候过于乐观自信的表现却是社会所迫。很多情况下承认自己的无知是不被接受的，比如cfo预测未来财政的时候。专家被认为就是要很有自信（这样的专家出镜率高🌚）。临床医学上也是这样，表现得不确定被认为是软弱的表现，医生宁愿显得自信，而不愿去和患者透露不确定性。很遗憾的是，尽管对于不确定性的没有偏差的评估是理性的根基，人们和社会却不想要这些😐
<blockquote>
<p>Acting on pretended knowledge is often the preferred solution.</p>
</blockquote>
高度乐观也可能有一定好处，比如Martin Seligman的乐观心理学提出乐观的解释方式能够提升自尊：简单来说，就是把成功都归结于自己，但是不把失败归结于自己🌚可能对于销售人员有帮助。<br>
另一个需要高度乐观的领域是科学研究：
<blockquote>
<p>I have yet to meet a successful scientist who lacks the ability to exaggerate the importance of what he or she is doing, and I believe that someone who lacks a delusional sense of significance will wilt in the face of repeated experiences of multiple small failures and rare successes, the fate of most researchers.</p>
</blockquote>
<p>说的太对了，我就是缺乏这种精神😂</p>

<p>最后，如果想要克服过度乐观带来的高风险决策，可以试试<em>premortem：</em> 在决策做完但是还没执行前给大家一个机会想想如果一年后失败了会是什么原因。这样给了大家一个在群体里合理提出质疑的机会，也给了大家一个抗争自己System 1的WYSIATI的机会。</p>
<h2>25 Bernoulli’s errors<br></h2>
<p>久违了，终于开始看第四部分关于决策。<br>
Kahneman和Tversky一起研究的成果里面最有名的大概就是<strong>prospect theory</strong> ，是研究人们面对不同简单赌博的选择以及在赌博和确定性之间的选择。<br>
在决策领域里面已经有了很有名的<strong><em>expected utility theory</em></strong> ，建立在人们是理性的基础之上：对于期望值相同的选项人们应该没有偏好。但是实际上并非如此：
<blockquote>
<p>Bernoulli observed that most people dislike risk and wish to avoid the worst outcome. &lsqb;...&rsqb; In fact a risk-averse decision maker will choose a sure thing that is less than expected value, in effect paying a premium to avoid the uncertainty.</p>
</blockquote>
</p>

<p><br>
Kahneman和Tversky的研究方式和德国心里学家Gustav Fechner在19世纪创立的psychophysics有点像。（Fechner的项目是寻找主观感受的变化和客观数量的变化的联系，他提出在很多维度这联系是logarithmic的。）但是要真的追溯起源，就要说到1738年瑞士科学家Daniel Bernoulli的<strong><em>moral expectation</em></strong> 理论：
<blockquote>
<p>people’s choices are based not on dollar values but on the psychological values of outcomes, their utilities. The psychological value of a gamble is therefore not the weighted average of its possible dollar outcomes; it is the average of the utilities of these outcomes, each weighted by its probability.</p>
</blockquote></p>

<p><br>
虽然Kahneman没直说，但是我用数学语言简单总结一下就是这样的：<br>
<code>因为utility函数是concave的，所以根据Jensen’s inequality期望值要比确定值低。</code><br>至于为什么utility是concave的，是因为财富越多的时候财富增长带来的回报越来越低（diminishing returns）。<br>
Bernoulli这个理论解释了为什么穷人愿意付出premium来买保险，把风险转移给卖保险的富人。
</p>

<p><br>那么为什么这章叫这个名字呢？因为虽然这个理论很好，但是也有很严重的问题，即它没有考虑到reference dependence：对于财富的感知是相对于一个参考点的（比如现有财富）。那么问题是那么多年为什么没有人严肃质疑呢？Kahneman自己反思说道：
<blockquote>
<p>I can explain it only by a weakness of the scholarly mind that I have often observed in myself. I call it <em>theory-induced blindness</em>: once you have accepted a theory and used it as a tool in your thinking, it is extraordinarily difficult to notice its flaws.</p>
</blockquote>
最后一句话我最喜欢：
<blockquote>
<p>As the psychologist Daniel Gilbert observed, <strong>disbelieving is hard work</strong>, and System 2 is easily tired.</p>
</blockquote>
</p>
<h2>26 Prospect theory<br></h2>
<p>来总结一下三点要素：<ol>
<li>Evaluation is relative to a neutral <strong>reference point</strong> , which is sometimes referred to as an “adaption level” (e.g., status quo, outcome that one expects or feels entitled to).<br>
<li>A principle of <strong>diminishing returns</strong>  applies to the evaluation of changes of wealth.<br>
<li><strong>Loss aversion</strong> : this asymmetry has an evolutionary history (better chance to survive and reproduce).</ol>
配图清晰得体现了这三点：<br>
<img src="https://drive.google.com/uc?id=1MokeENe66__0zuUjUiGfIhK9dly5aXDX" alt="Prospect Theory Figure" width=400>

<p>这个理论解释了为什么<br><ol>
<li>人们在面对有可能输赢的赌局时会表现得规避风险；<br>
<li>人们在面对两种都很糟的情况时(确定输一些vs可能输很多）会寻求风险。</ol>
</p>

<p><br>
关于损失规避，有趣的一点是这是可以通过“loss aversion ratio”来衡量的，比如说50%可能性输$100要用50%可能性赢$200来抵消的话这个比例就是2。一般人似乎是在1.5到2.5之间，但是职业金融交易员似乎会更容易接纳风险，于是这个比例也就更低一些。当然，这个比例也是因赌注而定：如果输的结果很惨或者会威胁生活，那么这个比例可能是∞，因为不管赢多少都不能接受这个风险。</p>

<p><br>2000年经济学家Matthew Rabin和Richard Thaler数学上证明了Bernoulli的utility theory无法解释人们损失规避的行为。（TODO：有空我要去看看他们具体怎么证明的。）</p>

<p><br>Kahneman最后还讨论了一下prospect theory的一些问题。首先为什么不在本科入门教科书里面教学生这些呢？因为1）怕学生反而更混乱，2）rational econs的模型虽然有时候不现实但是很多时候依然很有用。然后讨论了理论本身的缺点：不能解释失望和遗憾给人们带来的情绪波动和决策影响。<br>
最后他关于新的科学理论的思考我觉得很有道理：
<blockquote>
<p>Richer and more realistic assumptions do not suffice to make a theory successful. Scientists use theories as a bag of working tools, and they will not take on the burden of a heavier bag unless the new tools are very useful.</p></blockquote>
也就是说新的理论一定要比现有的理论好用很多很多才会被人接受。
</p>
<h2>27 The endowment effect <br></h2>
<p>首先看一下indifference curves，这个模型和Bernoulli犯了一样的错误，即其忽视了参照点的重要性，而假设我们的utility只和现状有关，无关历史。这是不合理的：<ol>
<li>喜好是会变的，尤其和参照点有关。<br>
<li>改变带来的坏处会比带来的好处影响更大，使人们更容易偏好保持现状。</ol>
</p>

<p>
<strong>Endowment effect</strong> 是Richard Thaler最先发现的，他发现一个教授最高愿意花35美元买的红酒，却在100美元都不愿意卖。拥有这瓶酒似乎增加了它的价值。他还发现了很多类似的🌰，尤其是不常交易的物品。这个现象可以用<strong>prospect theory</strong>解释：如果他拥有这瓶酒，他考虑的就是要放弃的痛苦；如果他还没拥有这瓶酒，他考虑的就是拥有它的愉悦 -- 两者价值是不等的，因为<strong>loss aversion</strong>，我们更害怕失去的痛苦。</p>

<p>但是并不是所有物品都有这种效果，比如我们帮人换零钱时并不会觉得用五个一块钱换了一张五块钱吃亏了。区别在于这个物品是用于交换的还是用于使用的。Thaler，Kahneman和Knetsch根据Vernon Smith的实验设计了一个实验，给一部分人每人一个本身价值六元的杯子，让另一部分人决定要不要买杯子，还有一部分人选择拿到杯子或者等值现金。结果卖杯子的人要价7.12元，买杯子的人出价2.87元，选择现金或者杯子的人估价3.13元。卖东西的时候人脑里面痛苦的那一部分会激活，买东西的时候如果价格过高这部分也会激活，反之如果低价买到东西是会带来喜悦的。有趣的是这个价格比例正好差不多是<strong>2：1</strong>，和人们在面临有风险的选择的时候的<strong>loss aversion系数</strong>差不多。</p>

<p>
<ul>
<li>那么我们可以避免endowment effect吗？如果我们把物品当做用于在未来交换的价值的载体，那么就可以避免了，就好比贸易和金融市场那样。有经验的交易员就可以减少/避免这个现象。<br></li>
<li>另外有趣的一点是Knetsch有实验表明只有当人们真正把物品拿在手里拥有的时候才会有这个现象。<br></li>
<li>虽然穷人和交易员有点像，不太有明显的endowment effect，但是原因却不一样：对于穷人，任何花费都是loss。<br></li>
<li>消费习惯，尤其是即兴消费和轻奢消费，和各国文化有关。在英国做的实验和在美国做的实验结果就相差很多。</li>
</ul>
</p>
<h2>28 Bad events <br></h2>
<p>一句话总结：坏的事情影响比好的大。
<hr>
关于amygdala：
<blockquote>
<p>the amygdala &lsqb;has&rsqb; the primary role as the “threat center” of the brain.</p>
</blockquote>
正好之前看如何鉴别psychopath那本书提到可能psychopath的大脑这部分有问题🤔
<hr>
关于🍒和蟑螂的不对称：笑死我了
<blockquote>
<p>The psychologist Paul Rozin, an expert on disgust, observed that a single cockroach will completely wreck the appeal of a bowl of cherries, but a cherry will do nothing at all for a  bowl of cockroaches.</p>
</blockquote>
<hr>
关于婚姻的5：1
<blockquote>
<p>Gottman estimated that a stable relationship requires that good interactions outnumber bad interactions by at least 5:1.</p>
</blockquote>
友情也是一样的道理，多年的感情可能一个瞬间毁掉😞
<hr>
关于追求目标：
<blockquote>
<p>The aversion to the failure of not reaching the goal is much stronger than the desire to exceed it.</p>
</blockquote>
关于改变现状的困难：
<blockquote>
<p>potential losers will be more active and determined than potential winners; the outcome will be biased in their favor...<br>
Loss aversion is a powerful conservative force that favors minimal changes from the status quo in the lives of both institutions and individuals.</p>
</blockquote>
<hr>
关于公平与否的判断：
<blockquote>
<p>we found &lsqb;that&rsqb; the exploitation of market power to impose losses on others is unacceptable.</p>
</blockquote>
但是公司自私的行为也是可以被理解的
<blockquote>
<p>When threatened, it is not unfair for the firm to be selfish. &lsqb;...&rsqb; it can pass &lsqb;losses&rsqb; on.</p>
</blockquote>
重点在于reference-dependent fairness。</p>

<h2>29 The fourfold pattern </h2>
<img src="https://drive.google.com/uc?id=1_UcMBxRYBh6j6w2TmZo1u5dk6CRVkHU1" alt="The Fourfold Pattern" width=600>

<p>总结：
<ul>
<li>The decision weights that people assign to outcomes are not identical to the probabilities of these outcomes, contrary to the expectation principle. <br></li>
<li><strong>Possibility effect</strong>: causes highly unlikely outcomes to be weighted disproportionately more than they “deserve”. 这就是为什么人们愿意花比预期多的钱买彩票🌝<br></li>
<li><strong>Certainty effect</strong>: outcomes that are almost certain are given less weight than their probability justifies. 这就是为什么人们买保险来换取确定性🌝</li>
</ul>

<h3>Allais’s paradox</h3>
<p>在1952年的一个会议上Maurice Allais提出的一个对于expectation principle的挑战，简化一下是这样的一组问题：<br>
<strong>A:</strong> 61%赢52万，或者63%赢50万<br>
<strong>B:</strong> 98%赢52万，或者100%赢50万 <br>
很多人都在A选了前者，而在B选了后者。这是不符合价值原则的，比较预期值都是前者高，而且B的差值还更大。但是通过certainty effect就可以解释在B选后者。<br>
有趣的是，我很一致的两个都选了后者😂</p>

<h3>决策权重</h3>
<img src="https://drive.google.com/uc?id=1zvm3JMfxX5YgL1o0oSsWN5R04eBckEgT" alt="Possibility and Certainty Effect" width=200>
<p>如图中蓝色所示，左边是possibility effect，右边是certainty effect。虽然两者的斜率都比黑色的1大，但是右边比左边的更甚之。我感觉这个和人们对于perceived loss比perceived gain更加看重有关。关于权重还有几点值得注意：<br>
<ul>
<li>极小概率事件会被特殊对待，要么被完全忽视掉（0权重），要么被扩大化（比如在媒体大幅报道一次恐怖袭击事件以后）。<br></li>
<li>人们往往对于极小概率之间的差别不敏感，比如十万分之一vs千万分之一。<br></li>
<li>当人们注意到威胁的时候会担忧，而担忧的程度会决定决策权重。</li>
</ul></p>

<p>
最后，回到四角示意图，右上角值得注意。这种在面对大概率损失追求风险的行为是不理智的，而且往往会带来灾难性后果。谨记及时止损。而右下角面对小概率损失规避风险的行为在长久看来也不可取，会带来积累的损失。总而言之
<blockquote>
<p>Systematic deviation from expected value are costly in the long run - and this rule applies to both risk aversion and risk seeking. <br>
<strong>Consistent overweighting of improbably outcomes - a feature of intuitive decision making - eventually leads to inferior outcomes.</strong> </p>
</blockquote>
</p>
<h2>30 Rare Events</h2>
<p><code>
    Focal attention and salience contribute to both the overestimation of unlikely events and the overweighting of unlikely outcomes.<br> 
    Salience is enhanced by mere mention of an event, by its vividness, and by the format in which probability is described.<br><br>
    And when there is no overweighting, there will be neglect.
 </code></p>

<p>
<ul>
<li>The psychology of high-prize lotteries is similar to the psychology of terrorism. <br></li>
<li>The probability of a rare event is most likely to be overestimated when the alternative is not fully specified. (比如说分别预测八个队夺冠的概率加起来有240%.) The successful execution of a plan is specific and easy to imagine when one tries to forecast the outcome of a project. In contrast, the alternative of failure is diffuse, because there are innumerable ways for things to go wrong. <br></li>
<li>A rich and vivid representation of the outcome, whether or not it is emotional, reduces the role of probability in the evaluation of an uncertain prospect. Adding irrelevant but vivid details to a monetary outcome also disrupts calculation.<br></li>
<li><em>Denominator neglect:</em> this explains why different ways of communicating risks vary so much in their effects. 比如说0.001%和1 in 100000相比后者冲击力大。The power of format creates opportunities for manipulation, which people with an axe to grind know how to exploit. ❗️警惕。<br></li>
<li>Choice from experience (相对于prospect理论关注的choices from description): the interpretation of choice from experience is not yet settled, but there is general agreement on one major cause of underweighting of rare events, both in experiments and in the real world: <strong>many participants never experience the rare event!</strong> <strong>Most Californians have never experienced a major earthquake. 😨</strong> </li>
</ul>
</p>
<h2>31 Risk policies</h2>
<p><code>Think like a trader. You win a few, you lose a few.</code><br>
<ul>
<li>Humans are by nature narrow framers (whereas rational agents engage in broad framing). 人们往往每次决策单独考虑而不是一系列决策整体考虑。<br></li>
<li>Because we are susceptible to WYSIATI and averse to mental effort, we tend to make decisions as problems arise... We have neither the inclination nor the mental resources to enforce consistency on our preferences, and our preferences are not magically set to be coherent.</li>
</ul></p>

<h3>Samuelson’s problem <br></h3>
<p>他的一个朋友说50/50概率赢200或者输100的赌博一次不会去赌，但是一百次的话会去赌。也就是说 <em>playing a very favorable but risky gamble multiple times reduces the subjective risk.</em>  Samuelson还去证明了在特定前提下根据rational model人如果拒绝一次也应该拒绝一百次。但是Rabin和Thaler指出一百次赌博的预期收益是5000，输钱的概率只有1/2300。为了表达risk aversion，我们把赔钱的数额✖️2，那么在一次赌博的情况下预期是0，而两次则是50，三次则是112.5。虽然损失规避程度不变，但是<strong>多次</strong>赌博快速降低了赔钱的风险，并且降低了损失规避对于决策偏好的影响。
</p>

<p>
记住这句话 <strong>you win a few, you lose a few</strong>. 在赔的时候注意控制自己的情绪。在需要面对预期为正的小的赌博的时候要提醒自己这一点。当然前提条件是1）这些赌博确实是相对独立的，2）是小额的不会产生对财富的担忧，3）不适于长期的赢的概率很小的赌博。在这些条件满足的情况下，要尽量像个交易员一样用broad framing来保护自己。损失规避➕narrow framing不仅会赔钱还会影响情绪：典型的面对坏消息的短期反应是增加损失规避的程度，频繁做出反应改变portfolio会导致盈利降低。
</p>

<h3>Risk policies</h3>
<p>风险政策可以帮助我们避免narrow framing，每次遇到决策就根据风险政策执行而不是单独做出（非最优）决策，比如永远不买延期保修。这个和outside view有点像，都是把眼前的单独的情况转化到整体的集合的情况用概率来考虑，但是后者是相反的方向：来避免过度乐观带来的planning fallacy。</p>
<h2>32 keeping score<br></h2>
<h3>Mental accounts</h3>
<ul>
<li>The ultimate currency that rewards or punishes is often emotional, a form of mental self-dealing.<br>
<li>For humans, mental accounts are a form of <strong><em>narrow framing</em></strong>: they keep things under control and manageable by a finite mind.<br>
<li>Financial research has documented a massive preference for selling winners rather than losers: </em></strong>the disposition effect</strong></em>.<br>
<li>Closing a mental account with a gain is a pleasure, but it is a pleasure you pay for. <br>
<li>The decision to invest additional resources in a losing account, when better investments are available, is known as <strong><em>the sunk-cost fallacy</em></strong>. 真的是道理都听过，但是就是很难做到。&lsqb;it&rsqb; keeps people for too long in poor jobs, unhappy marriages, and unpromising research projects. <br>
<li>&lsqb;when&rsqb; the choice is between a sure loss and an unfavorable gamble, &lsqb;the latter&rsqb; is often unwisely preferred.
</ul>

<h3>Regret</h3>
<li>Regret is an emotion, and it is also a punishment that we administer to ourselves.<br>
<li>Regret is one of the counterfactual emotions that are triggered by the availability of alternatives to reality. 越是不寻常的事情越容易引发后悔。<br>
<li>People expect to have stronger emotional reactions (including regret) to an outcome that is produced by action than to the same outcome when it is produced by inaction. <br>
<li>The asymmetry in the risk of regrets favors conventional and risk-averse choices.</p>

<h3>Responsibility </h3>
<ul>
<li>The <em>taboo tradeoff</em> against accepting any increase in risk is not an efficient way to use the safety budget. <br>
<li>But <em>enhanced loss aversion</em> is embedded in a strong and widely shared moral intuition; it originates in System 1. The dilemma between intensely loss-averse moral attitudes and efficient risk management does not have a simple and compelling solution.</ul>

<ul>
<li>Susceptibility to regret, like susceptibility to fainting spells, is a fact of life to which we must adjust.<br>
<li>Regret and hindsight bias will come together, so anything you can do to preclude hindsight is likely to be helpful. &lsqb;...&rsqb;  be either very thorough or completely casual when making a decision with long-term consequences. <br>
<li>Daniel Gilbert and his colleagues provocatively claim that people generally anticipate more regret than they will actually experience, because they underestimate the efficacy of the psychological defenses they will deploy --which they label the “<strong><em>psychological immune system</em></strong>”.</ul>
<h2>33 reversals</h2>

<p><code>We normally experience life in the between-subjects mode, in which contrasting alternatives that might change your minds are absent, and of course WYSIATI. As a consequence, the beliefs that you endorse when you reflect about morality do not necessarily govern your emotional reactions, and the moral intuitions that come to your mind in different situations are not internally consistent.</code></p>

<ul>
<li>Preference reversal occurs because joint evaluation focuses attention on an aspect of the situation which was less salient in single evaluation.<br></li>
<li>The emotional reactions of System 1 are more likely to determine single evaluation; the comparison that occurs in joint evaluation always involves a more careful and effortful assessment, which calls for System 2. <br></li>
<li>The process by which objects and events recruit their own context of comparison can lead to incoherent choices on serious matters. <br></li>
<li>Judgments and preferences are coherent within categories but potentially incoherent when the objects that are evaluated belong to different categories.</li>
</ul>

<ul>
<li>Rationality is generally served by broader and more comprehensive frames, and joint evaluation is obviously broader than single evaluation. <br>
<li>Except for such cases of deliberate manipulation (比如销售), there is a presumption that comparative judgment &lsqb;...&rsqb; is more likely to be stable than single evaluations. <br>
<li>The administration of justice is infected by predictable incoherence in several domains. &lsqb;...&rsqb; The legal system, contrary to psychological common sense, favors single evaluation.<br>
<li>The size of penalties varied greatly across agencies, in a manner that reflected politics and history more than any global concern for fairness. 严重违规员工安全条例的处罚最高$7000，而野生鸟类保护发令违规处罚可高达$25000。</p>
</ul>
<h2>34 frames and reality<br></h2>
<ul>
<li>The fact that logically equivalent statements evoke different reactions makes it impossible for Humans to be as reliably rational as Econs.<br></li>
<li>A bad outcome is much more acceptable if it is framed as the cost of a lottery ticket that did not win than if it is simply described as losing a gamble. <strong><em>Losses evoke stronger negative feelings than costs.</em></strong>（这是受到了Richard Thaler的研究启发。）<br></li>
<li>一项脑神经成像研究表明当研究对象的选择符合frame时脑部的情感区域是活跃的，而在选择不符合frame时脑部的冲突和自控区域是活跃的。有趣的是那些比较“理智”的人在复杂结合情感和分析的脑叶有活跃的活动。<br></li>
<li>不仅仅是普通人会受到framing的影响，专业人士也会，比如外科医生。</li>
</ul>

<ul>
<li>Reframing is effortful and System 2 is lazy. <strong>Unless there is obvious reason to do otherwise, most of us passively accept decision problems as they are framed and therefore rarely have an opportunity to discover the extent to which our preferences are</strong> <strong><em>frame-bound</em></strong> <strong>rather than</strong> <strong><em>reality-bound</em></strong><strong>.</strong> <br>
<li>当人们被明确指出他们在frame不同但是现实相同的情况下做出了不同选择的不一致表现时，人们往往只有尴尬的沉默，而并没有一个很好的道德直觉。<br>
<li><strong>Your moral feelings are attached to frames, to descriptions of reality rather than reality itself.</strong> &lsqb;...&rsqb;<strong>Framing should not be viewed as an intervention that masks or distorts an underlying preference</strong> &lsqb;...&rsqb;<strong>there is no underlying preference.</strong> 细思极恐🤔<br>
<li>当然这并不是说所有frame都是一样的，frame也有好有坏。此处立即想到了nudge的内容，果然Kahneman也简要概括了一下。怎么frame一个问题可能会取决于想要达到什么样的（政策）效果，比如器官捐赠。
</ul>
<h2>35 Two selves<br></h2>
<h3>Experienced utility</h3>
<p><code>Nature has placed mankind under the governance of two sovereign masters, pain and pleasure. It is for them alone to point out what we ought to do, as well as to determine what we shall do.</code><br>
(<em>Introduction to the Principles of Morals and Legislation</em>, Jeremy Bentham)</p>

<p>&lsqb;the&rsqb; assumption of coincidence &lsqb;of <em>experienced utility</em>  and <em>decision utility</em> &rsqb; is implicit in the general idea that economic agents are rational. 但是这一章要说的是其实并不是这样。</p>

<h3>Experience and memory</h3>
<ul>
<li>The British economist Francis Edgeworth proposed the idea of a “hedonimeter” which could measure the level of pleasure or pain that an individual experiences at any moment. Time plays a critical role in Edgeworth’s conception. （像积分那样考虑“area under the curve”. ）<br>
<li>然而实验发现人们在经历后的回忆感觉符合两个现象：<ul>
    <li><em>peak-end rule</em> ：最高峰和结束时的感觉主导了回忆里的感觉<br>
    <li><em>duration neglect</em> ：时间长短对于记忆里的感觉没啥影响</ul>
<li>这说明hedonimeter积分和事后评估有系统性差异 -- conflict of interests between <strong>two selves:</strong> the <strong><em>experiencing self</em></strong> and the <strong><em>remembering self</em></strong>. <br></li>
<li>Kahneman的点评让我有点唏嘘：<em>memories are all we get to keep from our experience of living, and the only perspective that we can adopt as we think about our lives is therefore that of the remembering self.</em></li>
</ul>

<ul>
<li>Confusing experience with memory of it is a compelling cognitive illusion - and it is the substitution that makes us believe a past experience can be ruined. What we learn from the past is to maximize the qualities of our future memories, not necessarily our future experience. <br>
<li>人们有些偏好反映出了<strong><em>less-is-more</em></strong> 的效果，因为System 1惯用平均值/代表值而不是总值来做决策。<br>
<li>为什么自然选择没有让动物的记忆里存储体验积分呢？有些时候是这样的，比如🐿️存过冬的食物，但是对于痛苦和欢乐的时间积分可能意义小一点吧。
</ul>
<p><code>
Tastes and decisions are shaped by memories, and memories can be wrong. A memory that neglects duration will not serve our preference for long pleasure and short pain. 🌝</code></p>
<h2>36 Life as a story <br></h2>

<p>故事只关注重要事件和值得回忆的时刻，而不是流逝的时光。人生经常被看作故事，而我们关心的经常是这个故事的质量，而不是当事人的感受：比如说一个男人临死前并不知道老婆出轨多年，尽管他活得一辈子很快乐，但是我们会同情他。（而且我感觉这个质量是根据我们自己的价值观强加在别人身上的😂）当然最重要的是我们都希望自己的人生是一个好的故事，有一个好的主人公。
</p>

<p><br>心理学家Ed Diener和他的学生做过一系列实验让人们根据一小段介绍来评价一个虚拟人物的一生。他们得到的结果是人们通常会用一个典型的时间片来评价，而不是一系列的时刻，也就是说人们看的是平均/典型，而不是总和。（但是我觉得这是具有相关性的，时间越长好的事情越多，而且其中高光的具有代表性的容易被记住的事件也越多，还是会有影响吧？）他们还发现了less-is-more的现象，加上一些没有那么快乐的时光会拉低平均值，导致故事没有那么好，尽管因为时间多了快乐总值其实提高了。（这大概就是那种宁愿耀眼地活短一点也不愿平凡地活长一点的想法？）所以总结一下就是人们对于别人一生的评价基本上是基于具有代表性的高光时刻和结局，而不太受到时间长短影响。（这是对于别人的评价，可惜我们无法对自己的一生做个评价。）</p>

<p><br>关于回忆：出去度假时留下回忆往往是很多人的重要目标，这个目标影响了旅行计划安排和体验。照片对于回忆的自己很有用（就算我们并没有我们以为得那样经常翻看照片），但是拍照可能对于体验的自己其实不是享受旅行的最佳选项。Kahneman提到的这句话很有意思：当我们有意识地创造值得回忆的经历时，这种行为本身就赋予了这个事件意义。回忆有多重要呢？重要到人们通常会根据回忆好坏来决定要不要重复一个体验（就算回忆因为之前提到的偏差是“错误”的）。如果失去回忆的话，很多经历都失去了很大的意义和价值。最后他说：尽管看着奇怪，我就是那个回忆的我，而那个体验的我，那个真正在活着的我，却仿佛像个陌生人。（这话听着有点忧伤啊😔）
</p>
<h2>37 Experienced well-being<br></h2>
<p>一般用于衡量幸福感的问卷是在问the remembering self, 于是作者想要衡量一下the experiencing self的幸福感。他们尝试了Csikszentmihalyi提出的experience sampling，但是这个方法太贵太麻烦，于是他们提出了Day Reconstruction Method (DRM), 通过详细访谈的方式来记录人一天的每项活动和感受。他们用U-index来计量人们在不开心的状态下的时间比例。他们惊奇地发现伤痛的情绪分布是很不平均的，有一小部分人承受了大部分的痛苦（这不是和财富分布一样吗lol）他们还发现注意力是关键。我们的情绪状态很大程度上取决于我们当下关注的活动和眼前的环境（当然也有例外，恋爱中的傻子就算堵车时候也是开心的）。这些观察说明人们可以掌控的自己的时间分配是很重要的，多做一些自己享受的事情可以改善情绪（道理都懂，做起来难）。并且这些数据还可以帮助政府制定社会政策来减低人们的不开心感。</p>

<p><br>衡量the experiencing self的幸福感的调查现在被各个国家广泛采用，采集了很多数据。可想而知头疼会让人痛苦，但是预测幸福感第二有效的预测信号是和朋友亲人的接触。他说到这句话很好：
<blockquote>
<p>It is only a slight exaggeration to say that happiness is the experience of spending time with people you love and who love you. ❤️</p>
</blockquote>
（但是在当下我们都在努力学着自己调节情绪，在独处的时候也可以使自己开心。）
</p>

<p><br>有一个有名的问题叫做Cantril Self-Achoring Striving Scale, 问的是现在自己的人生在十个台阶的哪里。Kahneman对比了这个问题的回答和the experiencing self的幸福感。有些观察很有趣：
<ul>
<li>教育程度越高阶梯越高，但是不一定感受到的幸福感越强（因为压力越大）。<br>
<li>身体疾病则对于幸福感有更大的影响。<br>
<li>相比于阶梯，宗教活动对于幸福感有更正面的影响。<br>
<li>钱可以买幸福吗？富有会提高人的满意度，但不会提高平均的幸福感。而贫困会放大其他的不幸事件带来的痛苦。<br>
<li>在收入达到一定程度后，继续增加收入不会提高人们感受到的幸福感，或许是因为这反而使人们失去了享受生活中那些小乐趣的能力。但是高收入会让人一直上升阶梯提高成就感。
</ul>
</p>
<h2>38 thinking about life<br></h2>
<p>这章开头是一幅生活满意度根据结婚时间的变化的图表，显示在结婚前两年升高，到结婚当年满意度最高，然后会下降。（此处没有交代具体方法，但是我觉得要谨慎考虑有没有confounder，比如和结婚相关的房贷啊养娃啊啥的😂 ）一般人决定结婚是因为他们希望婚姻可以使他们更幸福或者希望婚姻可以让他们一直享有当下的幸福感。然而决定结婚其实映射出了很多人的<strong><em>affective forecasting</em></strong> 的巨大错误（这个词由Daniel Gilbert和Timothy Wilson提出）。其实这些调查问卷的回答应该被谨慎考虑，因为人们很容易受到当下的心情，最近的或者即将发生的重大事件（比如结婚），以及反复发生的事件影响。于是这导致我们给自己的人生打的分数是被一小部分很容易想到的事情决定的，而不是仔细权衡所有事件决定的。重点在于<strong>注意力</strong> 。那个图表其实可以理解为人们在被问到人生满意度时有多大可能性会想到最近的结婚事件。</p>

<p><br>DRM研究的一个发现是结婚和单身女性体验到的幸福感总体没什么差别。这不是因为结婚对于幸福感没有影响，而是因为婚姻对于有些方面有所改善（比如陪伴），但是同时对于另一些方面有所伤害（比如做家务带孩子）。</p>

<p><br>个人境遇和幸福感的关联度低的一个原因在于幸福感很大程度上取决于遗传性格。<strong>目标</strong> 也有很大影响。那些想要钱而且赚到了钱的人会很满足，但是那些想要钱却没赚到的人会很不满足。其他的目标也是一样。所以作者给出温馨小贴士：<strong>不要设定那些很难实现的目标，那样很容易让你感到不满足。</strong> </p>

<p><br><strong><em>Focusing illusion</em></strong>: nothing in life is as important as you think it is when you are thinking about it. 人们在衡量自己的人生时想到的任何事都会得到很大的权重（不管是不是真的该有那么大权重）。这里的🌰是加州的好天气对于幸福感的影响。加州人比其他地方的人更开心吗？（现在看这个真的有点讽刺lol，想想今年的山火和疫情）他们对于几个州的学生做的调查发现这些人对于气候的重要性有着过于夸张的信念，实际上气候对于幸福感没什么影响。其实长期生活在加州的人并不会太注意气候，但是刚搬来的人（不管实际上是不是更开心）都会因为想到气候好而认为自己更开心（自欺欺人吗？但是只要骗到了也没啥问题吧）。另一个关于结肠造口术的调查表明尽管体验的自我对于一些经历并没有太大负面影响，但是记忆的自我却会受到很大的focusing illusion的影响而去极力避免这种经历再次发生。Gilbert和Wilson管这个现象叫做<strong><em>miswanting：</em></strong> 出于affective forecasting做出的坏的决定<strong><em>。</em></strong> </p>

<p><br>最后，时间是一个经常被忽略的因素。那些不随时间贬值的经历往往没有得到他们应得的欣赏。我们的头脑很擅长应对故事，但是却不那么擅长处理时间。</p>

<p><br>最后的最后，快乐这个词没有一个简单的定义，我们在说到快乐的时候也要注意这一点。</p>
<h2>Conclusions</h2>
<h3>Two selves <br></h3>
<ul>
<li>The central fact of our existence is that time is the finite resource, but the remembering self ignores that reality. <br></li>
<li>The remembering self’s neglect of duration, its exaggerated emphasis on peaks and ends, and its susceptibility to hindsight combine to yield distorted reflections of our actual experience. <br></li>
<li>We can determine only after the fact that a moment is memorable or meaningful. The statements “I will always remember...” &lsqb;...&rsqb; can be false, and often are -- even when uttered with complete sincerity.  🌚<br></li>
<li>The remembering self and the experiencing self must both be considered, because their interests do not always coincide.</li>
</ul>
<h3>Econs and humans <br></h3>
<ul>
<li>Rationality is logical coherence. Econs are rational by this definition, but there is overwhelming evidence that Humans cannot be. An Econ would not be susceptible to <strong><em>priming, WYSIATI, narrow framing, the inside view,</em></strong> or <strong><em>preference reversals</em></strong>, which Humans cannot consistently avoid. <br></li>
<li>Although humans are not irrational, they often need help to make more accurate judgments and better decisions, and in some cases policies and institutions can provide that help. <br></li>
<li>These claims &lsqb;above&rsqb; are in fact  quite controversial. Milton Friedman expressed this view &lsqb;that rational people should be free and responsible for taking care of themselves&rsqb; in &lsqb;his book&rsqb; <em>Free to Choose</em>.  <br></li>
<li>The assumption that agents are rational provides the intellectual foundation for the libertarian approach to public policy: do not interfere with the individual’s right to choose, unless the choices harm others 🙃.  <br></li>
<li>For behavioral economists, freedom has a cost, which is borne by individuals who make bad choices, <em>and by a society that feels obligated to help them 🙃</em>. The economists of the Chicago school do not face that problem, because rational agents do not make mistakes. Freedom is free of charge. <br></li>
<li>Thaler and Sunstein &lsqb;in their book <em>Nudge</em>&rsqb; advocate a position of libertarian paternalism, in which the state and other institutions are allowed to nudge people to make decisions that serve their own long-term interests.</li>
</ul>
<p>现在这个时候看这些评价真的很有共鸣😞</p>
<h3>Two systems<br></h3>
<ul>
<li>The attentive System 2 is who we think we are. System 2 articulates judgments and makes choices, but it often endorses or rationalizes ideas and feelings that were generated by System 1. System 2 also prevents many foolish thoughts and inappropriate impulses from overt expression. However, System 2’s abilities are limited and so is the knowledge to which it has access. <br></li>
<li>System 1 is indeed the origin of much that we do wrong, <em>but it is also the origin of most of what we do right</em> -- which is most of what we do.  <br></li>
<li>The acquisition of skills requires a regular environment, an adequate opportunity to practice, and rapid and unequivocal feedback about the correctness of thoughts and actions. When these conditions are fulfilled, skill eventually develops, and the intuitive judgments and choices that quickly come to mind will mostly be accurate. (或许AI还是有希望的🤔）<br></li>
<li>&lsqb;When System 1 employs heuristics&rsqb; the heuristic answer is not necessarily simpler or more frugal than the original question -- it is only <em>more</em> <em>accessible</em>, computed more quickly and easily. The heuristic answers are not random, and they are often approximated correct. And sometimes they are quite wrong. <br></li>
<li>System 1 registers the cognitive ease with which it processes information, but it does not generate a warning signal when it becomes unreliable. (我们需要confidence estimate！）System 2’s only recourse is to slow down and attempt to construct an answer on its own, which it is reluctant to do because <em>it is indolent</em>. Many suggestions of System 1 are casually endorsed with minimal checking. This is how System 1 acquires its bad reputation as the sources of errors and biases: <strong><em>WYSIATI, intensity matching</em></strong>, and <strong><em>associate coherence</em></strong>, among others, give rise to predictable biases and cognitive illusions such as <strong><em>anchoring</em></strong>, <strong><em>nonregressive predictions, over-confidence</em></strong>, and numerous others. <br></li>
<li>The way to block errors that originate in System 1 is simple in principle: recognize the signs that you are in a cognitive minefield, slow down, and ask for reinforcement from System 2. Unfortunately, this sensible procedure is least likely to be applied when it is needed the most. The upshot is that it is much easier to identity a minefield when you observe others wandering into it than when you are about to do so. <br></li>
<li>Ultimately, a richer language is essential to the skill of constructive criticism. Much like medicine, the identification of judgment errors is a diagnostic task, which requires a precise vocabulary. (aka这本书😄）</li>
</ul>
<p><br></p>
